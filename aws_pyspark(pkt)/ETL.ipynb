{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#from pyspark.sql.functions import lit,col,explode\n",
    "import pyspark.sql.functions as f \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://avinash:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ETL Pipeline</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x27631e51670>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract\n",
    "\n",
    "spark = SparkSession.builder.appName(\"ETL Pipeline\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------+\n",
      "|value                                                                                    |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "|This is a Japanese doll                                                                  |\n",
      "|The team members were hard to tell apart since they all wore their hair in a ponytail    |\n",
      "|As the years pass by we all know owners look more and more like their dogs               |\n",
      "|If you don't like toenails you probably shouldn't look at your feet                      |\n",
      "|He was disappointed when he found the beach to be so sandy and the sun so sunny          |\n",
      "|When he encountered maize for the first time he thought it incredibly corny              |\n",
      "|Situps are a terrible way to end your day                                                |\n",
      "|Toddlers feeding raccoons surprised even the seasoned park ranger                        |\n",
      "|Edith could decide if she should paint her teeth or brush her nails                      |\n",
      "|Her daily goal was to improve on yesterday                                               |\n",
      "|Tomorrow will bring something new so leave today as a memory                             |\n",
      "|His son quipped that power bars were nothing more than adult candy bars                  |\n",
      "|He wondered why at 18 he was old enough to go to war but not old enough to buy cigarettes|\n",
      "|If my calculator had a history it would be more embarrassing than my browser history     |\n",
      "|The hummingbird's wings blurred while it eagerly sipped the sugar water from the feeder  |\n",
      "|He went on a whiskey diet and immediately lost three days                                |\n",
      "|This is the last random sentence I will be writing and I am going to stop mid-sent       |\n",
      "|I come from a tribe of head-hunters so I will never need a shrink                        |\n",
      "|The delicious aroma from the kitchen was ruined by cigarette smoke                       |\n",
      "|Weather is not trivial - it's especially important when you're standing in it            |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.text(\"data/WordData1.txt\")\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|words|count|\n",
      "+-----+-----+\n",
      "|   to|   88|\n",
      "|  the|   76|\n",
      "|    a|   76|\n",
      "|  was|   44|\n",
      "|   is|   40|\n",
      "|   he|   40|\n",
      "|   it|   36|\n",
      "|  The|   32|\n",
      "|   He|   28|\n",
      "| that|   28|\n",
      "|  and|   28|\n",
      "|   so|   24|\n",
      "|  you|   24|\n",
      "|   in|   24|\n",
      "|   of|   24|\n",
      "|    I|   24|\n",
      "|  her|   24|\n",
      "|   be|   24|\n",
      "|   if|   20|\n",
      "| when|   16|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"splitdata\",f.split(\"value\",\" \"))\\\n",
    "    .withColumn(\"words\",f.explode(\"splitdata\"))\\\n",
    "    .select(\"words\").groupBy(\"words\").count()\\\n",
    "    .alias(\"count_word\").orderBy(\"count\",ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+\n",
      "|               value|           splitdata|   words|\n",
      "+--------------------+--------------------+--------+\n",
      "|This is a Japanes...|[This, is, a, Jap...|    This|\n",
      "|This is a Japanes...|[This, is, a, Jap...|      is|\n",
      "|This is a Japanes...|[This, is, a, Jap...|       a|\n",
      "|This is a Japanes...|[This, is, a, Jap...|Japanese|\n",
      "|This is a Japanes...|[This, is, a, Jap...|    doll|\n",
      "|The team members ...|[The, team, membe...|     The|\n",
      "|The team members ...|[The, team, membe...|    team|\n",
      "|The team members ...|[The, team, membe...| members|\n",
      "|The team members ...|[The, team, membe...|    were|\n",
      "|The team members ...|[The, team, membe...|    hard|\n",
      "|The team members ...|[The, team, membe...|      to|\n",
      "|The team members ...|[The, team, membe...|    tell|\n",
      "|The team members ...|[The, team, membe...|   apart|\n",
      "|The team members ...|[The, team, membe...|   since|\n",
      "|The team members ...|[The, team, membe...|    they|\n",
      "|The team members ...|[The, team, membe...|     all|\n",
      "|The team members ...|[The, team, membe...|    wore|\n",
      "|The team members ...|[The, team, membe...|   their|\n",
      "|The team members ...|[The, team, membe...|    hair|\n",
      "|The team members ...|[The, team, membe...|      in|\n",
      "+--------------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tranformatin \n",
    "df2 = df.withColumn(\"splitdata\",f.split(\"value\",\" \"))\n",
    "df2.withColumn(\"words\",f.explode(\"splitdata\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|   words|\n",
      "+--------+\n",
      "|    This|\n",
      "|      is|\n",
      "|       a|\n",
      "|Japanese|\n",
      "|    doll|\n",
      "|     The|\n",
      "|    team|\n",
      "| members|\n",
      "|    were|\n",
      "|    hard|\n",
      "|      to|\n",
      "|    tell|\n",
      "|   apart|\n",
      "|   since|\n",
      "|    they|\n",
      "|     all|\n",
      "|    wore|\n",
      "|   their|\n",
      "|    hair|\n",
      "|      in|\n",
      "+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# transformation\n",
    "df2 = df.withColumn('splitedData',f.split('value',' '))\n",
    "df3 = df2.withColumn('words',explode('splitedData'))\n",
    "word_df = df3.select('words')\n",
    "word_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = word_df.groupBy('words').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD \n",
    "driver = \"com.mysql.jdbc.Driver\"\n",
    "url = 'jdbc:mysql://database-2.cjbysn8oqrq1.us-east-1.rds.amazonaws.com/'\n",
    "table = 'avinash_schema.wordcount'\n",
    "user='admin'\n",
    "password='ad789min'\n",
    "\n",
    "word_count.write.mode('append').format(\"jdbc\").option(\"url\",url).option(\"driver\",driver)\\\n",
    "    .option(\"dbtable\",table).option(\"mode\",\"append\").option(\"user\",user)\\\n",
    "        .option(\"password\",password).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD \n",
    "driver1 = \"com.mysql.jdbc.Driver\"\n",
    "url1 = 'jdbc:mysql://localhost:3306/'\n",
    "table1 = 'study.wordcount'\n",
    "user1='root'\n",
    "password1='root'\n",
    "\n",
    "# word_count.write.mode('append').format('jdbc').option(\"url\",url1)\\\n",
    "#     .option(\"driver\",driver1)\\\n",
    "#     .option('dbtable',table1).option('mode','append').option('user',user1)\\\n",
    "#         .option('password',password1).save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[first_name: string, last_name: string, company_name: string, address: string, city: string, country: string, state: string, zip: string, age: string, phone1: string, phone2: string, email: string, web: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read mysql table\n",
    "df_tbl = spark.read\\\n",
    "            .format(\"jdbc\")\\\n",
    "            .option(\"url\",\"jdbc:mysql://localhost/bigdata\")\\\n",
    "            .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\\\n",
    "            .option(\"dbtable\",\"usdata\")\\\n",
    "            .option(\"user\",\"root\")\\\n",
    "            .option(\"password\",\"root\")\\\n",
    "            .load()\n",
    "df_tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tbl.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book_id', 'title', 'price']\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession\\\n",
    "#     .builder\\\n",
    "#     .appName(\"Word Count\")\\\n",
    "#     .getOrCreate()\n",
    "\n",
    "dataframe_mysql = spark.read\\\n",
    "    .format(\"jdbc\")\\\n",
    "    .option(\"url\", \"jdbc:mysql://localhost/exam\")\\\n",
    "    .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\\\n",
    "    .option(\"dbtable\", \"books\").option(\"user\", \"root\")\\\n",
    "    .option(\"password\", \"root\").load()\n",
    "\n",
    "print(dataframe_mysql.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+-----+\n",
      "|book_id|               title|price|\n",
      "+-------+--------------------+-----+\n",
      "|  12345|  Python Programming|   29|\n",
      "|  12346|         Learn MySQL|   23|\n",
      "|  12347|Data Science Cook...|   27|\n",
      "|  12367|           My dreams|   50|\n",
      "|  13456|       Eat that frog|   34|\n",
      "+-------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe_mysql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(num):\n",
    "    if num<1:\n",
    "        return 0\n",
    "    elif num%2==0:\n",
    "        return fun(num-1)\n",
    "    else:\n",
    "        return num+fun(num-2)\n",
    "\n",
    "fun(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Python3 program for the above approach\n",
    "def max_profit(prices: list, days: int) -> int:\n",
    "  \n",
    "    profit = 0\n",
    "  \n",
    "    for i in range(1, days):\n",
    "  \n",
    "        # checks if elements are adjacent and in increasing order\n",
    "        if prices[i] > prices[i-1]:\n",
    "  \n",
    "            # difference added to 'profit'\n",
    "            profit += prices[i] - prices[i-1]\n",
    "  \n",
    "    return profit\n",
    "\n",
    "def StockPicker(arr):\n",
    "    min_price = float('inf')\n",
    "    max_profit = -1\n",
    "    for price in arr:\n",
    "        min_price = min(min_price, price)\n",
    "        max_profit = max(max_profit, price - min_price)\n",
    "    return max_profit if max_profit > 0 else -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "in12 = [10,12,4,5,9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_profit(in12,len(in12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
